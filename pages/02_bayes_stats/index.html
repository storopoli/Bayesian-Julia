<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/Bayesian-Julia/libs/katex/katex.min.css"> <link rel=stylesheet  href="/Bayesian-Julia/libs/highlight/github.min.css"> <link rel=stylesheet  href="/Bayesian-Julia/css/jtd.css"> <link rel=icon  href="/Bayesian-Julia/assets/favicon.ico"> <title>What is Bayesian Statistics?</title> <div class=page-wrap > <div class=side-bar > <div class=header > <a href="/Bayesian-Julia/" class=title > Bayesian Stats </a> </div> <label for=show-menu  class=show-menu >MENU</label> <input type=checkbox  id=show-menu  role=button > <div class=menu  id=side-menu > <ul class=menu-list > <li class="menu-list-item "><a href="/Bayesian-Julia/" class="menu-list-link ">Home</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/01_why_Julia/" class="menu-list-link ">1. Why Julia?</a> <li class="menu-list-item active"><a href="/Bayesian-Julia/pages/02_bayes_stats/" class="menu-list-link active">2. What is Bayesian Statistics?</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/03_prob_dist/" class="menu-list-link ">3. Common Probability Distributions</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/04_Turing/" class="menu-list-link ">4. How to use Turing</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/05_MCMC/" class="menu-list-link ">5. Markov Chain Monte Carlo (MCMC)</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/06_linear_reg/" class="menu-list-link ">6. Bayesian Linear Regression</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/07_logistic_reg/" class="menu-list-link ">7. Bayesian Logistic Regression</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/08_ordinal_reg/" class="menu-list-link ">8. Bayesian Ordinal Regression</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/09_count_reg/" class="menu-list-link ">9. Bayesian Regression with Count Data</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/10_robust_reg/" class="menu-list-link ">10. Robust Bayesian Regression</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/11_multilevel_models/" class="menu-list-link ">11. Multilevel Models</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/12_Turing_tricks/" class="menu-list-link ">12. Computational Tricks with Turing</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/13_epi_models/" class="menu-list-link ">13. Bayesian Epidemiological Models</a> </ul> </div> <div class=footer > <a href="https://www.julialang.org"><img style="height:50px;padding-left:10px;margin-bottom:15px;" src="https://julialang.org/assets/infra/logo.svg" alt="Julia Logo"></a> </div> </div> <div class=main-content-wrap > <div class=main-content > <div class=main-header > <a id=github  href="https://github.com/storopoli/Bayesian-Julia">Code on GitHub</a> </div> <div class=franklin-content ><div class=franklin-toc ><ol><li><a href="#what_is_probability">What is Probability?</a><ol><li><a href="#mathematical_definition">Mathematical Definition</a><li><a href="#conditional_probability">Conditional Probability</a><li><a href="#joint_probability">Joint Probability</a><li><a href="#bayes_theorem">Bayes&#39; Theorem</a><li><a href="#discrete_vs_continuous_parameters">Discrete vs Continuous Parameters</a></ol><li><a href="#bayesian_statistics">Bayesian Statistics</a><li><a href="#frequentist_statistics">Frequentist Statistics</a><ol><li><a href="#p-values"><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values</a><li><a href="#what_the_p-value_is_not">What the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is not</a><li><a href="#confidence_intervals">Confidence Intervals</a></ol><li><a href="#bayesian_statistics_vs_frequentist_statistics">Bayesian Statistics vs Frequentist Statistics</a><li><a href="#advantages_of_bayesian_statistics">Advantages of Bayesian Statistics</a><li><a href="#the_beginning_of_the_end_of_frequentist_statistics">The beginning of the end of Frequentist Statistics</a><li><a href="#turing">Turing</a><li><a href="#footnotes">Footnotes</a><li><a href="#references">References</a></ol></div> <h1 id=what_is_bayesian_statistics ><a href="#what_is_bayesian_statistics" class=header-anchor >What is Bayesian Statistics?</a></h1> <p><strong>Bayesian statistics</strong> is an approach to inferential statistics based on Bayes&#39; theorem, where available knowledge about parameters in a statistical model is updated with the information in observed data. The background knowledge is expressed as a prior distribution and combined with observational data in the form of a likelihood function to determine the posterior distribution. The posterior can also be used for making predictions about future events.</p> <p><strong>Bayesian statistics</strong> is a departure from classical inferential statistics that prohibits probability statements about parameters and is based on asymptotically sampling infinite samples from a theoretical population and finding parameter values that maximize the likelihood function. Mostly notorious is null-hypothesis significance testing &#40;NHST&#41; based on <em>p</em>-values. Bayesian statistics <strong>incorporate uncertainty</strong> &#40;and prior knowledge&#41; by allowing probability statements about parameters, and the process of parameter value inference is a direct result of the <strong>Bayes&#39; theorem</strong>.</p> <p>Bayesian statistics is <strong>revolutionizing all fields of evidence-based science</strong><sup id="fnref:evidencebased"><a href="#fndef:evidencebased" class=fnref >[1]</a></sup> &#40;van de Schoot et al., 2021&#41;. Dissatisfaction with traditional methods of statistical inference &#40;frequentist statistics&#41; and the advent of computers with exponential growth in computing power<sup id="fnref:computingpower"><a href="#fndef:computingpower" class=fnref >[2]</a></sup> provided a rise in Bayesian statistics because it is an approach aligned with the human intuition of uncertainty, robust to scientific malpractices, but computationally intensive.</p> <p>But before we get into Bayesian statistics, we have to talk about <strong>probability</strong>: the engine of Bayesian inference.</p> <h2 id=what_is_probability ><a href="#what_is_probability" class=header-anchor >What is Probability?</a></h2> <blockquote> <p>PROBABILITY DOES NOT EXIST&#33; <br/> <br/> de Finetti &#40;1974&#41;<sup id="fnref:deFinetti"><a href="#fndef:deFinetti" class=fnref >[3]</a></sup></p> </blockquote> <p>These are the first words in the preface to the famous book by <a href="https://en.wikipedia.org/wiki/Bruno_de_Finetti">Bruno de Finetti</a> &#40;figure below&#41;, one of the most important probability mathematician and philosopher. Yes, probability does not exist. Or rather, probability as a physical quantity, objective chance, <strong>does NOT exist</strong>. De Finetti showed that, in a precise sense, if we dispense with the question of objective chance <em>nothing is lost</em>. The mathematics of inductive reasoning remains <strong>exactly the same</strong>.</p> <p><img src="/Bayesian-Julia/pages/images/finetti.jpg" alt="De Finetti" /></p> <p><div class=text-center ><em>Bruno de Finetti</em></div> <br/></p> <p>Consider tossing a weighted coin. The attempts are considered independent and, as a result, exhibit another important property: <strong>the order does not matter</strong>. To say that order does not matter is to say that if you take any finite sequence of heads and tails and exchange the results however you want, the resulting sequence will have the same probability. We say that this probability is <strong>invariant under permutations</strong>.</p> <p>Or, to put it another way, the only thing that matters is the relative frequency. Result that have the same frequency of heads and tails consequently have the same probability. The frequency is considered a <strong>sufficient statistic</strong>. Saying that order doesn&#39;t matter or saying that the only thing that matters is frequency are two ways of saying exactly the same thing. This property is called <strong>exchangeability</strong> by de Finetti. And it is the most important property of probability that makes it possible for us to manipulate it mathematically &#40;or philosophically&#41; even if it does not exist as a physical &quot;thing&quot;.</p> <p>Still developing the argument:</p> <blockquote> <p>&quot;Probabilistic reasoning - always understood as subjective - stems merely from our being uncertain about something. It makes no difference whether the uncertainty relates to an unforeseeable future <sup id="fnref:subjective"><a href="#fndef:subjective" class=fnref >[4]</a></sup>, or to an unnoticed past, or to a past doubtfully reported or forgotten <sup id="fnref:objective"><a href="#fndef:objective" class=fnref >[5]</a></sup>... The only relevant thing is uncertainty - the extent of our own knowledge and ignorance. The actual fact of whether or not the events considered are in some sense determined, or known by other people, and so on, is of no consequence.&quot; &#40;de Finetti, 1974&#41;</p> </blockquote> <p>In conclusion: no matter what the probability is, you can use it anyway, even if it is an absolute frequency &#40;ex: probability that I will ride my bike naked is ZERO because the probability that an event that never occurred will occur in the future it is ZERO&#41; or a subjective guess &#40;ex: maybe the probability is not ZERO, but 0.00000000000001; very unlikely, but not impossible&#41;.</p> <h3 id=mathematical_definition ><a href="#mathematical_definition" class=header-anchor >Mathematical Definition</a></h3> <p>With the philosophical intuition of probability elaborated, we move on to <strong>mathematical intuitions</strong>. The probability of an event is a real number<sup id="fnref:realnumber"><a href="#fndef:realnumber" class=fnref >[6]</a></sup>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∈</mo><mi mathvariant=double-struck >R</mi></mrow><annotation encoding="application/x-tex">\in \mathbb{R}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.5782em;vertical-align:-0.0391em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.68889em;vertical-align:0em;"></span><span class="mord mathbb">R</span></span></span></span> between 0 and 1, where, roughly, 0 indicates the impossibility of the event and 1 indicates the certainty of the event. The greater the likelihood of an event, the more likely it is that the event will occur. A simple example is the tossing of a fair &#40;impartial&#41; coin. Since the coin is fair, both results &#40;&quot;heads&quot; and &quot;tails&quot;&#41; are equally likely; the probability of &quot;heads&quot; is equal to the probability of &quot;tails&quot;; and since no other result is possible<sup id="fnref:mutually"><a href="#fndef:mutually" class=fnref >[7]</a></sup>, the probability of &quot;heads&quot; or &quot;tails&quot; is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{2}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.190108em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> &#40;which can also be written as 0.5 or 50&#37;&#41;.</p> <p>Regarding notation, we define <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> as an event and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(A)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span></span> as the probability of event <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span>, thus:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mo stretchy=false >{</mo><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>∈</mo><mi mathvariant=double-struck >R</mi><mo>:</mo><mn>0</mn><mo>≤</mo><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>≤</mo><mn>1</mn><mo stretchy=false >}</mo><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex">\{P(A) \in \mathbb{R} : 0 \leq P(A) \leq 1 \}.</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >{</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.68889em;vertical-align:0em;"></span><span class="mord mathbb">R</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >:</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.78041em;vertical-align:-0.13597em;"></span><span class=mord >0</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >≤</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >≤</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord >1</span><span class=mclose >}</span><span class=mord >.</span></span></span></span></span> <p>This means the &quot;probability of the event to occur is the set of all real numbers between 0 and 1; including 0 and 1&quot;. In addition, we have three axioms<sup id="fnref:axioms"><a href="#fndef:axioms" class=fnref >[8]</a></sup>, originated from Kolmogorov&#40;1933&#41; &#40;figure below&#41;:</p> <ol> <li><p><strong>Non-negativity</strong>: For all <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">P(A) \geq 0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >≥</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0</span></span></span></span>. Every probability is positive &#40;greater than or equal to zero&#41;, regardless of the event.</p> <li><p><strong>Additivity</strong>: For two mutually exclusive <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> &#40;cannot occur at the same time<sup id="fnref:mutually2"><a href="#fndef:mutually2" class=fnref >[9]</a></sup>&#41;: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(A) = 1 - P(B)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.72777em;vertical-align:-0.08333em;"></span><span class=mord >1</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo stretchy=false >)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(B) = 1 - P(A)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.72777em;vertical-align:-0.08333em;"></span><span class=mord >1</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span></span>.</p> <li><p><strong>Normalization</strong>: The probability of all possible events <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub><mo separator=true >,</mo><msub><mi>A</mi><mn>2</mn></msub><mo separator=true >,</mo><mo>…</mo></mrow><annotation encoding="application/x-tex">A_1, A_2, \dots</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class=mord ><span class="mord mathnormal">A</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathnormal">A</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner >…</span></span></span></span> must add up to 1: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mrow><mi>n</mi><mo>∈</mo><mi mathvariant=double-struck >N</mi></mrow></msub><mi>P</mi><mo stretchy=false >(</mo><msub><mi>A</mi><mi>n</mi></msub><mo stretchy=false >)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\sum_{n \in \mathbb{N}} P(A_n) = 1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.07708em;vertical-align:-0.32708000000000004em;"></span><span class=mop ><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.18251299999999993em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">∈</span><span class="mord mathbb mtight">N</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.32708000000000004em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal">A</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >1</span></span></span></span>.</p> </ol> <p><img src="/Bayesian-Julia/pages/images/kolmogorov.jpg" alt="Andrey Nikolaevich Kolmogorov" /></p> <p><div class=text-center ><em>Andrey Nikolaevich Kolmogorov</em></div> <br/></p> <p>With these three simple &#40;and intuitive&#41; axioms, we are able to <strong>derive and construct all the mathematics of probability</strong>.</p> <h3 id=conditional_probability ><a href="#conditional_probability" class=header-anchor >Conditional Probability</a></h3> <p>An important concept is the <strong>conditional probability</strong> that we can define as the &quot;probability that one event will occur if another has occurred or not&quot;. The notation we use is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo>∣</mo><mi>B</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> P(A \mid B)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span></span>, which reads as &quot;the probability that we have observed <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> given we have already observed <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>&quot;.</p> <p>A good example is the <a href="https://en.wikipedia.org/wiki/Texas_hold_&#37;27em">Texas Hold&#39;em Poker game</a>, where the player receives two cards and can use five &quot;community cards&quot; to set up his &quot;hand&quot;. The probability that you are dealt a King &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>&#41; is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>4</mn><mn>52</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{4}{52}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.190108em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>:</p> <a id=king  class=anchor ></a><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>K</mi><mo stretchy=false >)</mo><mo>=</mo><mrow><mo fence=true >(</mo><mfrac><mn>4</mn><mn>52</mn></mfrac><mo fence=true >)</mo></mrow><mo>=</mo><mrow><mo fence=true >(</mo><mfrac><mn>1</mn><mn>13</mn></mfrac><mo fence=true >)</mo></mrow><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> P(K) = \left(\frac{4}{52}\right) = \left(\frac{1}{13}\right) . </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.40003em;vertical-align:-0.95003em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >52</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >4</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.40003em;vertical-align:-0.95003em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >13</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >.</span></span></span></span></span> <p>And the probability of being dealt an Ace is also the same as <span class=eqref >(<a href="#king">2</a>)</span>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>4</mn><mn>52</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{4}{52}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.190108em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">52</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>:</p> <a id=ace  class=anchor ></a><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>=</mo><mrow><mo fence=true >(</mo><mfrac><mn>4</mn><mn>52</mn></mfrac><mo fence=true >)</mo></mrow><mo>=</mo><mrow><mo fence=true >(</mo><mfrac><mn>1</mn><mn>13</mn></mfrac><mo fence=true >)</mo></mrow><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> P(A) = \left(\frac{4}{52}\right) = \left(\frac{1}{13}\right) . </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.40003em;vertical-align:-0.95003em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >52</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >4</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.40003em;vertical-align:-0.95003em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >13</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >.</span></span></span></span></span> <p>However, the probability that you are dealt a King as a second card since you have been dealt an Ace as a first card is:</p> <a id=kingace  class=anchor ></a><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>K</mi><mo>∣</mo><mi>A</mi><mo stretchy=false >)</mo><mo>=</mo><mrow><mo fence=true >(</mo><mfrac><mn>4</mn><mn>51</mn></mfrac><mo fence=true >)</mo></mrow><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> P(K \mid A) = \left(\frac{4}{51}\right) . </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.40003em;vertical-align:-0.95003em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >51</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >4</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >.</span></span></span></span></span> <p>Since we have one less card &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>52</mn><mo>−</mo><mn>1</mn><mo>=</mo><mn>51</mn></mrow><annotation encoding="application/x-tex">52 - 1 = 51</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.72777em;vertical-align:-0.08333em;"></span><span class=mord >52</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >1</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >51</span></span></span></span>&#41; because you have been dealt already an Ace &#40;thus <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> has been observed&#41;, we have 4 Kings still in the deck, so the <span class=eqref >(<a href="#kingace">4</a>)</span> is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>4</mn><mn>51</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{4}{51}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.190108em;vertical-align:-0.345em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">51</span></span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>.</p> <h3 id=joint_probability ><a href="#joint_probability" class=header-anchor >Joint Probability</a></h3> <p>Conditional probability leads us to another important concept: joint probability. <strong>Joint probability is the &quot;probability that two events will both occur&quot;</strong>. Continuing with our Poker example, the probability that you will receive two cards, Ace &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span>&#41; and a King &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>&#41; as two starting cards is:</p> <a id=aceandking  class=anchor ></a><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.2500em  columnalign="right left" columnspacing=0em ><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo separator=true >,</mo><mi>K</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>K</mi><mo>∣</mo><mi>A</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mrow><mo fence=true >(</mo><mfrac><mn>1</mn><mn>13</mn></mfrac><mo fence=true >)</mo></mrow><mo>⋅</mo><mi>P</mi><mrow><mo fence=true >(</mo><mfrac><mn>4</mn><mn>51</mn></mfrac><mo fence=true >)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mrow><mo fence=true >(</mo><mfrac><mn>4</mn><mrow><mn>51</mn><mo>⋅</mo><mn>13</mn></mrow></mfrac><mo fence=true >)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>≈</mo><mn>0.006.</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{aligned} P(A,K) &amp;= P(A) \cdot P(K \mid A) \\ &amp;= P \left(\frac{1}{13}\right) \cdot P \left(\frac{4}{51}\right)\\ &amp;= P \left(\frac{4}{51 \cdot 13}\right) \\ &amp;\approx 0.006 . \end{aligned} </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:8.40006em;vertical-align:-3.950030000000001em;"></span><span class=mord ><span class=mtable ><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:4.45003em;"><span style="top:-7.06003em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mclose >)</span></span></span><span style="top:-4.95003em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ></span></span><span style="top:-2.2499999999999996em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ></span></span><span style="top:-0.1599699999999995em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:3.950030000000001em;"><span></span></span></span></span></span><span class=col-align-l ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:4.45003em;"><span style="top:-7.06003em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span><span style="top:-4.95003em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >13</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >51</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >4</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span><span style="top:-2.2499999999999996em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >51</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mord >13</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >4</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span><span style="top:-0.1599699999999995em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >≈</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mord >0.006.</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:3.950030000000001em;"><span></span></span></span></span></span></span></span></span></span></span></span> <p>Note that <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo separator=true >,</mo><mi>K</mi><mo stretchy=false >)</mo><mo>=</mo><mi>P</mi><mo stretchy=false >(</mo><mi>K</mi><mo separator=true >,</mo><mi>A</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(A,K) = P(K,A)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span></span>:</p> <a id=kingandace  class=anchor ></a><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.2500em  columnalign="right left" columnspacing=0em ><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>K</mi><mo separator=true >,</mo><mi>A</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mo stretchy=false >(</mo><mi>K</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo>∣</mo><mi>K</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mrow><mo fence=true >(</mo><mfrac><mn>1</mn><mn>13</mn></mfrac><mo fence=true >)</mo></mrow><mo>⋅</mo><mi>P</mi><mrow><mo fence=true >(</mo><mfrac><mn>4</mn><mn>51</mn></mfrac><mo fence=true >)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mrow><mo fence=true >(</mo><mfrac><mn>4</mn><mrow><mn>51</mn><mo>⋅</mo><mn>13</mn></mrow></mfrac><mo fence=true >)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>≈</mo><mn>0.006.</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{aligned} P(K,A) &amp;= P(K) \cdot P(A \mid K) \\ &amp;= P \left(\frac{1}{13}\right) \cdot P \left(\frac{4}{51}\right)\\ &amp;= P \left(\frac{4}{51 \cdot 13}\right) \\ &amp;\approx 0.006 . \end{aligned} </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:8.40006em;vertical-align:-3.950030000000001em;"></span><span class=mord ><span class=mtable ><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:4.45003em;"><span style="top:-7.06003em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span><span style="top:-4.95003em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ></span></span><span style="top:-2.2499999999999996em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ></span></span><span style="top:-0.1599699999999995em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:3.950030000000001em;"><span></span></span></span></span></span><span class=col-align-l ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:4.45003em;"><span style="top:-7.06003em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mclose >)</span></span></span><span style="top:-4.95003em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >13</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >51</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >4</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span><span style="top:-2.2499999999999996em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.32144em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >51</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mord >13</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >4</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span><span style="top:-0.1599699999999995em;"><span class=pstrut  style="height:3.45em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >≈</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mord >0.006.</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:3.950030000000001em;"><span></span></span></span></span></span></span></span></span></span></span></span> <p>But this symmetry does not always exist &#40;in fact it very rarely exists&#41;. The identity we have is as follows:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>K</mi><mo>∣</mo><mi>A</mi><mo stretchy=false >)</mo><mo>=</mo><mi>P</mi><mo stretchy=false >(</mo><mi>K</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo>∣</mo><mi>K</mi><mo stretchy=false >)</mo><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> P(A) \cdot P(K \mid A) = P(K) \cdot P(A \mid K) . </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mclose >)</span><span class=mord >.</span></span></span></span></span> <p>So this symmetry only exists when the baseline rates for conditional events are equal:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>=</mo><mi>P</mi><mo stretchy=false >(</mo><mi>K</mi><mo stretchy=false >)</mo><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> P(A) = P(K). </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mclose >)</span><span class=mord >.</span></span></span></span></span> <p>Which is what happens in our example.</p> <h4 id=conditional_probability_is_not_commutative ><a href="#conditional_probability_is_not_commutative" class=header-anchor >Conditional Probability is not &quot;commutative&quot;</a></h4> <a id=noncommutative  class=anchor ></a><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo>∣</mo><mi>B</mi><mo stretchy=false >)</mo><mo mathvariant=normal >≠</mo><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo>∣</mo><mi>A</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> P(A \mid B) \neq P(B \mid A) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel ><span class=mrel ><span class="mord vbox"><span class=thinbox ><span class=rlap ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=inner ><span class=mord ><span class=mrel ></span></span></span><span class=fix ></span></span></span></span></span><span class=mrel >=</span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span></span></span> <p>Let&#39;s see a practical example. For example, I’m feeling good and start coughing in line at the supermarket. What do you think will happen? Everyone will think I have COVID, which is equivalent to thinking about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mtext>cough</mtext><mo>∣</mo><mtext>covid</mtext><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(\text{cough} \mid \text{covid})</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord text"><span class=mord >cough</span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >covid</span></span><span class=mclose >)</span></span></span></span>. Seeing the most common symptoms of COVID, <strong>if you have COVID, the chance of coughing is very high</strong>. But we actually cough a lot more often than we have COVID – <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mtext>cough</mtext><mo stretchy=false >)</mo><mo mathvariant=normal >≠</mo><mi>P</mi><mo stretchy=false >(</mo><mtext>COVID</mtext><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(\text{cough}) \neq P(\text{COVID})</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord text"><span class=mord >cough</span></span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel ><span class=mrel ><span class="mord vbox"><span class=thinbox ><span class=rlap ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=inner ><span class=mord ><span class=mrel ></span></span></span><span class=fix ></span></span></span></span></span><span class=mrel >=</span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord text"><span class=mord >COVID</span></span><span class=mclose >)</span></span></span></span>, so:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mtext>COVID</mtext><mo>∣</mo><mtext>cough</mtext><mo stretchy=false >)</mo><mo mathvariant=normal >≠</mo><mi>P</mi><mo stretchy=false >(</mo><mtext>cough</mtext><mo>∣</mo><mtext>COVID</mtext><mo stretchy=false >)</mo><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> P(\text{COVID} \mid \text{cough}) \neq P(\text{cough} \mid \text{COVID}) . </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord text"><span class=mord >COVID</span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >cough</span></span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel ><span class=mrel ><span class="mord vbox"><span class=thinbox ><span class=rlap ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=inner ><span class=mord ><span class=mrel ></span></span></span><span class=fix ></span></span></span></span></span><span class=mrel >=</span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord text"><span class=mord >cough</span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >COVID</span></span><span class=mclose >)</span><span class=mord >.</span></span></span></span></span> <h3 id=bayes_theorem ><a href="#bayes_theorem" class=header-anchor >Bayes&#39; Theorem</a></h3> <p>This is the last concept of probability that we need to address before diving into Bayesian statistics, but it is the most important. Note that it is not a semantic coincidence that Bayesian statistics and Bayes&#39; theorem have the same prefix.</p> <p><a href="https://en.wikipedia.org/wiki/Thomas_Bayes">Thomas Bayes</a> &#40;1701 - 1761, figure below&#41; was an English Presbyterian statistician, philosopher and minister known for formulating a specific case of the theorem that bears his name: Bayes&#39; theorem. Bayes never published what would become his most famous accomplishment; his notes were edited and published after his death by his friend Richard Price<sup id="fnref:thomaspricelaplace"><a href="#fndef:thomaspricelaplace" class=fnref >[10]</a></sup>. In his later years, Bayes was deeply interested in probability. Some speculate that he was motivated to refute David Hume&#39;s argument against belief in miracles based on evidence from the testimony in &quot;An Inquiry Concerning Human Understanding&quot;.</p> <p><img src="/Bayesian-Julia/pages/images/thomas_bayes.gif" alt="Thomas Bayes" /></p> <p><div class=text-center ><em>Thomas Bayes</em></div> <br/></p> <p>Let&#39;s move on to Theorem. Remember that we have the following identity in probability:</p> <a id=jointidentity  class=anchor ></a><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.2500em  columnalign="right left" columnspacing=0em ><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo separator=true >,</mo><mi>B</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo separator=true >,</mo><mi>A</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo>∣</mo><mi>A</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo>∣</mo><mi>B</mi><mo stretchy=false >)</mo><mi mathvariant=normal >.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{aligned} P(A,B) &amp;= P(B,A) \\ P(A) \cdot P(B \mid A) &amp;= P(B) \cdot P(A \mid B) . \end{aligned} </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:3.0000000000000004em;vertical-align:-1.2500000000000002em;"></span><span class=mord ><span class=mtable ><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.7500000000000002em;"><span style="top:-3.91em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span><span style="top:-2.41em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.2500000000000002em;"><span></span></span></span></span></span><span class=col-align-l ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.7500000000000002em;"><span style="top:-3.91em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span><span style="top:-2.41em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span><span class=mord >.</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.2500000000000002em;"><span></span></span></span></span></span></span></span></span></span></span></span> <p>Ok, now move <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(B)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span></span> in the right of <span class=eqref >(<a href="#jointidentity">11</a>)</span> to the left as a division:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mtable rowspacing=0.2500em  columnalign="right left" columnspacing=0em ><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo>∣</mo><mi>A</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mover><mover><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo stretchy=false >)</mo></mrow><mo stretchy=true >undefined</mo></mover><mrow><mtext>this goes to </mtext><mstyle scriptlevel=0  displaystyle=false ><mo>←</mo></mstyle></mrow></mover><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo>∣</mo><mi>B</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mfrac><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo>∣</mo><mi>A</mi><mo stretchy=false >)</mo></mrow><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo stretchy=false >)</mo></mrow></mfrac></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo>∣</mo><mi>B</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo>∣</mo><mi>B</mi><mo stretchy=false >)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=0  displaystyle=true ><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo>∣</mo><mi>A</mi><mo stretchy=false >)</mo></mrow><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo stretchy=false >)</mo></mrow></mfrac><mi mathvariant=normal >.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{aligned} P(A) \cdot P(B \mid A) &amp;= \overbrace{P(B)}^{\text{this goes to $\leftarrow$}} \cdot P(A \mid B) \\ &amp;\\ \frac{P(A) \cdot P(B \mid A)}{P(B)} &amp;= P(A \mid B) \\ P(A \mid B) &amp;= \frac{P(A) \cdot P(B \mid A)}{P(B)}. \end{aligned} </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:9.706216000000001em;vertical-align:-4.603108000000001em;"></span><span class=mord ><span class=mtable ><span class=col-align-r ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:5.103108000000001em;"><span style="top:-7.103108000000001em;"><span class=pstrut  style="height:4.220216em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span><span style="top:-5.603108000000001em;"><span class=pstrut  style="height:4.220216em;"></span><span class=mord ></span></span><span style="top:-3.5161079999999996em;"><span class=pstrut  style="height:4.220216em;"></span><span class=mord ><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.427em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-0.8531079999999993em;"><span class=pstrut  style="height:4.220216em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:4.603108000000001em;"><span></span></span></span></span></span><span class=col-align-l ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:5.103108000000001em;"><span style="top:-7.103108000000001em;"><span class=pstrut  style="height:4.220216em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mover"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:2.2202159999999997em;"><span style="top:-3.398em;"><span class=pstrut  style="height:3.398em;"></span><span class="mord mover"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3980000000000001em;"><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span><span class=svg-align  style="top:-3.85em;"><span class=pstrut  style="height:3em;"></span><span class=stretchy  style="height:0.548em;min-width:1.6em;"><span class=brace-left  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M6 548l-6-6v-35l6-11c56-104 135.3-181.3 238-232 57.3-28.7 117 -45 179-50h399577v120H403c-43.3 7-81 15-113 26-100.7 33-179.7 91-237 174-2.7 5-6 9-10 13-.7 1-7.3 1-20 1H6z'/></svg></span><span class=brace-center  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M200428 334 c-100.7-8.3-195.3-44-280-108-55.3-42-101.7-93-139-153l-9-14c-2.7 4-5.7 8.7-9 14 -53.3 86.7-123.7 153-211 199-66.7 36-137.3 56.3-212 62H0V214h199568c178.3-11.7 311.7-78.3 403-201 6-8 9.7-12 11-12 .7-.7 6.7-1 18-1s17.3.3 18 1c1.3 0 5 4 11 12 44.7 59.3 101.3 106.3 170 141s145.3 54.3 229 60h199572v120z'/></svg></span><span class=brace-right  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M400000 542l -6 6h-17c-12.7 0-19.3-.3-20-1-4-4-7.3-8.3-10-13-35.3-51.3-80.8-93.8-136.5-127.5 s-117.2-55.8-184.5-66.5c-.7 0-2-.3-4-1-18.7-2.7-76-4.3-172-5H0V214h399571l6 1 c124.7 8 235 61.7 331 161 31.3 33.3 59.7 72.7 85 118l7 13v35z'/></svg></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.25em;"><span></span></span></span></span></span></span><span style="top:-5.132108000000001em;"><span class=pstrut  style="height:3.398em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">this goes to </span><span class="mspace mtight" style="margin-right:0.3252777777777778em;"></span><span class="mrel sizing reset-size3 size6">←</span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.25em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span><span style="top:-5.603108000000001em;"><span class=pstrut  style="height:4.220216em;"></span><span class=mord ><span class=mord ></span></span></span><span style="top:-3.5161079999999996em;"><span class=pstrut  style="height:4.220216em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span><span style="top:-0.8531079999999993em;"><span class=pstrut  style="height:4.220216em;"></span><span class=mord ><span class=mord ></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.427em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mord >.</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:4.603108000000001em;"><span></span></span></span></span></span></span></span></span></span></span></span> <p>And the final result is:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo>∣</mo><mi>B</mi><mo stretchy=false >)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>A</mi><mo stretchy=false >)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo>∣</mo><mi>A</mi><mo stretchy=false >)</mo></mrow><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>B</mi><mo stretchy=false >)</mo></mrow></mfrac><mi mathvariant=normal >.</mi></mrow><annotation encoding="application/x-tex"> P(A \mid B) = \frac{P(A) \cdot P(B \mid A)}{P(B)}. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:2.363em;vertical-align:-0.936em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.427em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mclose >)</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal">A</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal">A</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mord >.</span></span></span></span></span> <p>Bayesian statistics uses this theorem as <strong>inference engine</strong> of <strong>parameters</strong> of a model <strong>conditioned</strong> on <strong>observed data</strong>.</p> <h3 id=discrete_vs_continuous_parameters ><a href="#discrete_vs_continuous_parameters" class=header-anchor >Discrete vs Continuous Parameters</a></h3> <p>Everything that has been exposed so far is based on the assumption that the parameters are discrete. This was done in order to provide a better intuition of what is probability. We do not always work with discrete parameters. The parameters can be continuous, for example: age, height, weight, etc. But don&#39;t despair, all the rules and axioms of probability are also valid for continuous parameters. The only thing we have to do is to exchange all the sums <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo></mrow><annotation encoding="application/x-tex">\sum</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span></span></span></span> for integrals <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∫</mo></mrow><annotation encoding="application/x-tex">\int</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.11112em;vertical-align:-0.30612em;"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;">∫</span></span></span></span>. For example, the third axiom of <strong>Normalization</strong> for continuous random variables becomes:</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><msub><mo>∫</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></msub><mi>p</mi><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo><mi>d</mi><mi>x</mi><mo>=</mo><mn>1.</mn></mrow><annotation encoding="application/x-tex"> \int_{x \in X} p(x) dx = 1 . </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.29932em;vertical-align:-0.9393199999999999em;"></span><span class=mop ><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:-0.433619em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.9393199999999999em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class=mopen >(</span><span class="mord mathnormal">x</span><span class=mclose >)</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >1.</span></span></span></span></span> <h2 id=bayesian_statistics ><a href="#bayesian_statistics" class=header-anchor >Bayesian Statistics</a></h2> <p>Now that you know what probability is and what Bayes&#39; theorem is, I will propose the following model:</p> <a id=bayesianstats  class=anchor ></a><span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><munder><munder><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>θ</mi><mo>∣</mo><mi>y</mi><mo stretchy=false >)</mo></mrow><mo stretchy=true >undefined</mo></munder><mtext>Posterior</mtext></munder><mo>=</mo><mfrac><mrow><mover><mover><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>y</mi><mo>∣</mo><mi>θ</mi><mo stretchy=false >)</mo></mrow><mo stretchy=true >undefined</mo></mover><mtext>Likelihood</mtext></mover><mo>⋅</mo><mover><mover><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>θ</mi><mo stretchy=false >)</mo></mrow><mo stretchy=true >undefined</mo></mover><mtext>Prior</mtext></mover></mrow><munder><munder><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>y</mi><mo stretchy=false >)</mo></mrow><mo stretchy=true >undefined</mo></munder><mtext>Normalizing Constant</mtext></munder></mfrac><mo separator=true >,</mo></mrow><annotation encoding="application/x-tex"> \underbrace{P(\theta \mid y)}_{\text{Posterior}} = \frac{\overbrace{P(y \mid \theta)}^{\text{Likelihood}} \cdot \overbrace{P(\theta)}^{\text{Prior}}}{\underbrace{P(y)}_{\text{Normalizing Constant}}} , </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.3263309999999997em;vertical-align:-1.5763310000000001em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.7499999999999998em;"><span style="top:-1.4236689999999999em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Posterior</span></span></span></span></span><span style="top:-2.9999999999999996em;"><span class=pstrut  style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.75em;"><span class=svg-align  style="top:-2.102em;"><span class=pstrut  style="height:3em;"></span><span class=stretchy  style="height:0.548em;min-width:1.6em;"><span class=brace-left  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7 -331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z'/></svg></span><span class=brace-center  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M199572 214 c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0 -5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z'/></svg></span><span class=brace-right  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237 -174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z'/></svg></span></span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.898em;"><span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.5763310000000001em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:5.167324000000001em;vertical-align:-2.406216em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:2.761108em;"><span style="top:-3.3981080000000006em;"><span class=pstrut  style="height:4.0841080000000005em;"></span><span class=mord ><span class="mord munder"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.75em;"><span style="top:-1.415892em;"><span class=pstrut  style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Normalizing Constant</span></span></span></span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.75em;"><span class=svg-align  style="top:-2.102em;"><span class=pstrut  style="height:3em;"></span><span class=stretchy  style="height:0.548em;min-width:1.6em;"><span class=brace-left  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7 -331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z'/></svg></span><span class=brace-center  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M199572 214 c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0 -5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z'/></svg></span><span class=brace-right  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237 -174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z'/></svg></span></span></span><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >)</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.898em;"><span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.720216em;"><span></span></span></span></span></span></span></span><span style="top:-4.314108000000001em;"><span class=pstrut  style="height:4.0841080000000005em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-4.761108em;"><span class=pstrut  style="height:4.0841080000000005em;"></span><span class=mord ><span class="mord mover"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:2.084108em;"><span style="top:-3.398em;"><span class=pstrut  style="height:3.398em;"></span><span class="mord mover"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3980000000000001em;"><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mclose >)</span></span></span><span class=svg-align  style="top:-3.85em;"><span class=pstrut  style="height:3em;"></span><span class=stretchy  style="height:0.548em;min-width:1.6em;"><span class=brace-left  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M6 548l-6-6v-35l6-11c56-104 135.3-181.3 238-232 57.3-28.7 117 -45 179-50h399577v120H403c-43.3 7-81 15-113 26-100.7 33-179.7 91-237 174-2.7 5-6 9-10 13-.7 1-7.3 1-20 1H6z'/></svg></span><span class=brace-center  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M200428 334 c-100.7-8.3-195.3-44-280-108-55.3-42-101.7-93-139-153l-9-14c-2.7 4-5.7 8.7-9 14 -53.3 86.7-123.7 153-211 199-66.7 36-137.3 56.3-212 62H0V214h199568c178.3-11.7 311.7-78.3 403-201 6-8 9.7-12 11-12 .7-.7 6.7-1 18-1s17.3.3 18 1c1.3 0 5 4 11 12 44.7 59.3 101.3 106.3 170 141s145.3 54.3 229 60h199572v120z'/></svg></span><span class=brace-right  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M400000 542l -6 6h-17c-12.7 0-19.3-.3-20-1-4-4-7.3-8.3-10-13-35.3-51.3-80.8-93.8-136.5-127.5 s-117.2-55.8-184.5-66.5c-.7 0-2-.3-4-1-18.7-2.7-76-4.3-172-5H0V214h399571l6 1 c124.7 8 235 61.7 331 161 31.3 33.3 59.7 72.7 85 118l7 13v35z'/></svg></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.25em;"><span></span></span></span></span></span></span><span style="top:-4.996em;"><span class=pstrut  style="height:3.398em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Likelihood</span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.25em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >⋅</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class="mord mover"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:2.076331em;"><span style="top:-3.398em;"><span class=pstrut  style="height:3.398em;"></span><span class="mord mover"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3980000000000001em;"><span style="top:-3em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mclose >)</span></span></span><span class=svg-align  style="top:-3.85em;"><span class=pstrut  style="height:3em;"></span><span class=stretchy  style="height:0.548em;min-width:1.6em;"><span class=brace-left  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M6 548l-6-6v-35l6-11c56-104 135.3-181.3 238-232 57.3-28.7 117 -45 179-50h399577v120H403c-43.3 7-81 15-113 26-100.7 33-179.7 91-237 174-2.7 5-6 9-10 13-.7 1-7.3 1-20 1H6z'/></svg></span><span class=brace-center  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M200428 334 c-100.7-8.3-195.3-44-280-108-55.3-42-101.7-93-139-153l-9-14c-2.7 4-5.7 8.7-9 14 -53.3 86.7-123.7 153-211 199-66.7 36-137.3 56.3-212 62H0V214h199568c178.3-11.7 311.7-78.3 403-201 6-8 9.7-12 11-12 .7-.7 6.7-1 18-1s17.3.3 18 1c1.3 0 5 4 11 12 44.7 59.3 101.3 106.3 170 141s145.3 54.3 229 60h199572v120z'/></svg></span><span class=brace-right  style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M400000 542l -6 6h-17c-12.7 0-19.3-.3-20-1-4-4-7.3-8.3-10-13-35.3-51.3-80.8-93.8-136.5-127.5 s-117.2-55.8-184.5-66.5c-.7 0-2-.3-4-1-18.7-2.7-76-4.3-172-5H0V214h399571l6 1 c124.7 8 235 61.7 331 161 31.3 33.3 59.7 72.7 85 118l7 13v35z'/></svg></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.25em;"><span></span></span></span></span></span></span><span style="top:-4.996em;"><span class=pstrut  style="height:3.398em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Prior</span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.25em;"><span></span></span></span></span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:2.406216em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mpunct >,</span></span></span></span></span> <p>where:</p> <ul> <li><p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> – parameter&#40;s&#41; of interest;</p> <li><p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> – observed data;</p> <li><p><strong>Prior</strong> – previous probability of the parameter value&#40;s&#41;<sup id="fnref:prior"><a href="#fndef:prior" class=fnref >[11]</a></sup> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>;</p> <li><p><strong>Likelihood</strong> – probability of the observed data <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> conditioned on the parameter value&#40;s&#41; <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>;</p> <li><p><strong>Posterior</strong> – posterior probability of the parameter value&#40;s&#41; <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> after observing the data <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span>; and</p> <li><p><strong>Normalizing Constant</strong> – <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>y</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(y)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >)</span></span></span></span> does not make intuitive sense. This probability is transformed and can be interpreted as something that exists only so that the result of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>y</mi><mo>∣</mo><mi>θ</mi><mo stretchy=false >)</mo><mi>P</mi><mo stretchy=false >(</mo><mi>θ</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(y \mid \theta) P(\theta)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mclose >)</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mclose >)</span></span></span></span> is somewhere between 0 and 1 – a valid probability by the axioms. We will talk more about this constant in <a href="/Bayesian-Julia/pages/5_MCMC/">5. <strong>Markov Chain Monte Carlo &#40;MCMC&#41;</strong></a>.</p> </ul> <p>Bayesian statistics allow us <strong>to directly quantify the uncertainty</strong> related to the value of one or more parameters of our model conditioned to the observed data. This is the <strong>main feature</strong> of Bayesian statistics, for we are directly estimating <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>θ</mi><mo>∣</mo><mi>y</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P (\theta \mid y)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >)</span></span></span></span> using Bayes&#39; theorem. The resulting estimate is totally intuitive: it simply quantifies the uncertainty we have about the value of one or more parameters conditioned on the data, the assumptions of our model &#40;likelihood&#41; and the previous probability&#40;prior&#41; we have about such values.</p> <h2 id=frequentist_statistics ><a href="#frequentist_statistics" class=header-anchor >Frequentist Statistics</a></h2> <p>To contrast with Bayesian statistics, let&#39;s look at the frequentist statistics, also known as &quot;classical statistics&quot;. And already take notice: <strong>it is not something intuitive</strong> like the Bayesian statistics.</p> <p>For frequentist statistics, the researcher is <strong>prohibited from making probabilistic conjectures about parameters</strong>. Because they are not uncertain, quite the contrary they are determined quantities. The only issue is that we do not directly observe the parameters, but they are deterministic and do not allow any margin of uncertainty. Therefore, for the frequentist approach, parameters are unobserved amounts of interest in which we do not make probabilistic conjectures.</p> <p>What, then, is uncertain in frequentist statistics? Short answer: <strong>the observed data</strong>. For the frequentist approach, the sample is uncertain. Thus, we can only make probabilistic conjectures about our sample. Therefore, the uncertainty is expressed in the probability that I will obtain data similar to those that I obtained if I sampled from a population of interest infinite samples of the same size as my sample<sup id="fnref:warning"><a href="#fndef:warning" class=fnref >[12]</a></sup>. Uncertainty is conditioned by a frequentist approach, in other words, uncertainty only exists only if I consider an infinite sampling process and extract a frequency from that process. <strong>The probability only exists if it represents a frequency</strong>. Frequentist statistics is based on an &quot;infinite sampling process of a population that I have never seen&quot;, strange that it may sounds.</p> <p>For the frequentist approach, there is no <em>posterior</em> or <em>prior</em> probability since both involve parameters, and we saw that this is a no-no on frequentist soil. Everything that is necessary for statistical inference is <strong>contained within likelihood</strong><sup id="fnref:likelihoodsubj"><a href="#fndef:likelihoodsubj" class=fnref >[13]</a></sup>.</p> <p>In addition, for reasons of ease of computation, since most of these methods were invented in the first half of the 20th century &#40;without any help of a computer&#41;, only the parameter value&#40;s&#41; that maximize&#40;s&#41; the likelihood function is&#40;are&#41; computed<sup id="fnref:likelihoodopt"><a href="#fndef:likelihoodopt" class=fnref >[14]</a></sup>. From this optimization process we extracted the <strong>mode</strong> of the likelihood function &#40;<em>i.e.</em> maximum value&#41;. The maximum likelihood estimate &#40;MLE&#41; is&#40;are&#41; the parameter value&#40;s&#41; so that a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>-sized sample randomly sampled from a population &#40;<em>i.e.</em> the data you&#39;ve collected&#41; is the most likely <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>-sized sample from that population. All other potential samples that could be extracted from this population will have a worse estimate than the sample you actually have<sup id="fnref:warning2"><a href="#fndef:warning2" class=fnref >[15]</a></sup>. In other words, we are conditioning the parameter value&#40;s&#41; on the observed data from the assumption that we are sampling infinite <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>-sized samples from a theoretical population and treating the parameter values as fixed and our sample as random &#40;or uncertain&#41;.</p> <p>The mode works perfectly in the fairytale world, which assumes that everything follows a normal distribution, in which the mode is equal to the median and to the mean – <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>mean</mtext><mo>=</mo><mtext>median</mtext><mo>=</mo><mtext>mode</mtext></mrow><annotation encoding="application/x-tex">\text{mean} = \text{median} = \text{mode}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord text"><span class=mord >mean</span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class=mord >median</span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord text"><span class=mord >mode</span></span></span></span></span>. There is only one problem, this assumption is rarely true &#40;see figure below&#41;, especially when we are dealing with multiple parameters with complex relationships between them &#40;complex models&#41;.</p> <p><img src="/Bayesian-Julia/pages/images/assumptions-vs-reality.jpeg" alt="Assumptions vs Reality" /></p> <p><div class=text-center ><em>Assumptions vs Reality. Figure by <a href="https://www.khstats.com/blog/tmle/tutorial/">Katherine Hoffman</a>. Authorized Reproduction</em></div> <br/></p> <p>A brief sociological and computational explanation is worthwhile of why frequentist &#40;classical&#41; statistics prohibit probabilistic conjectures about parameters and we are only left with optimizing &#40;finding the maximum value of a function&#41; rather than approximating or estimating a <strong>complete likelihood density</strong> &#40;in other words, &quot;to pull up the whole file&quot; of the likelihood verisimilitude instead of just the mode&#41;.</p> <p>On the sociological side of things, science at the beginning of the 20th century assumed that it should be strictly objective and all subjectivity must be banned. Therefore, since the estimation of the a posterior probability of parameters involves elucidating an a prior probability of parameters, such a method should not be allowed in science, as it brings subjectivity &#40;we know today that nothing in human behavior is purely objective, and subjectivity permeates all human endeavors&#41;.</p> <p>Regarding the computational side of things, in the 1930s without computers it was much easier to use strong assumptions about the data to get a value from a statistical estimation using mathematical derivations than to calculate the statistical estimation by hand without depending on such assumptions. For example: Student&#39;s famous <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> test is a test that indicates when we can reject that the mean of a certain parameter of interest between two groups is equal &#40;famous null hypothesis - <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">H_0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>&#41;. This test starts from the assumption that if the parameter of interest is distributed according to a normal distribution &#40;assumption 1 – normality of the dependent variable&#41;, if the variance of the parameter of interest varies homogeneously between groups &#40;assumption 2 – homogeneity of the variances&#41;, and if the number of observations in the two groups are similar &#40;assumption 3 – homogeneity of the size of the groups&#41; the difference between the groups weighted by the variance of the groups follows a Student-<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> distribution &#40;hence the name of the test&#41;.</p> <p>So statistical estimation comes down to calculating the average of two groups, the variance of both groups for a parameter of interest and looking for the associated <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value in a table and see if we can reject the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">H_0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. This was valid when everything we had to do was calculated by hand. Today, with a computer 1 million times more powerful than the Apollo 11 computer &#40;one that took humanity to the moon&#41; in your pocket <sup id="fnref:computingpower"><a href="#fndef:computingpower" class=fnref >[2]</a></sup>, I don&#39;t know if it is still valid.</p> <h3 id=p-values ><a href="#p-values" class=header-anchor ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values</a></h3> <blockquote> <p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values are hard to understand, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&lt;</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">p &lt; 0.05</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >&lt;</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0.05</span></span></span></span>.</p> </blockquote> <p><img src="/Bayesian-Julia/pages/images/meme-pvalue2.jpg" alt="p-values are hard to understand" /></p> <p>Since I&#39;ve mentioned the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> word, let me explain what it is. First, the correct<sup id="fnref:booksp"><a href="#fndef:booksp" class=fnref >[16]</a></sup> statistics textbook definition:</p> <blockquote> <p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is the probability of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypothesis is correct.</p> </blockquote> <p>Unfortunately with frequentist statistics you have to choose one of two qualities for explanations: intuitive or accurate<sup id="fnref:gelman"><a href="#fndef:gelman" class=fnref >[17]</a></sup>.</p> <p>If you write this definition in any test, book or scientific paper, you are 100&#37; accurate and correct in defining what a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is. Now, understanding this definition is complicated. For that, let&#39;s break this definition down into parts for a better understanding:</p> <ul> <li><p><strong>&quot;probability of obtaining test results..&quot;</strong>: notice that <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values are related your data and not your theory or hypothesis.</p> <li><p><strong>&quot;...at least as extreme as the results actually observed...&quot;</strong>: &quot;at least as extreme&quot; implies defining a threshold for the characterization of some relevant finding, which is commonly called <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>. We generally stipulate alpha at 5&#37; &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.05</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0.05</span></span></span></span>&#41; and anything more extreme than alpha &#40;ie less than 5&#37;&#41; we characterize as <strong>significant</strong>.</p> <li><p><strong>&quot;... under the assumption that the null hypothesis is correct.&quot;</strong>: every statistical test that has a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value has a null hypothesis &#40;usually written as <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">H_0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>&#41;. Null hypotheses, always have to do with some <strong>null effect</strong>. For example, the null hypothesis of the Shapiro-Wilk and Komolgorov-Smirnov test is &quot;the data is distributed according to a Normal distribution&quot; and that of the Levene test is &quot;the group variances are equal&quot;. Whenever you see a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value, ask yourself: &quot;What is the null hypothesis that this test assumes is correct?&quot;.</p> </ul> <p>To understand the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value any statistical test first find out what is the null hypothesis behind that test. The definition of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value will not change. In every test it is always the same. What changes with the test is the null hypothesis. Each test has its <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">H_0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. For example, some common statistical tests &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mtext>D</mtext><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\text{D}^*</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.761926em;vertical-align:0em;"></span><span class=mord ><span class="mord text"><span class=mord >D</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.761926em;"><span style="top:-3.1362300000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> &#61; data at least as extreme as the results actually observed&#41;:</p> <ul> <li><p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> Test: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><msup><mtext>D</mtext><mo>∗</mo></msup><mo>∣</mo><mtext>the difference between groups are zero</mtext><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(\text{D}^* \mid \text{the difference between groups are zero})</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0119259999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class=mord ><span class="mord text"><span class=mord >D</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.761926em;"><span style="top:-3.1362300000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >the difference between groups are zero</span></span><span class=mclose >)</span></span></span></span></p> <li><p>ANOVA: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><msup><mtext>D</mtext><mo>∗</mo></msup><mo>∣</mo><mtext>there is no difference between groups</mtext><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(\text{D}^* \mid \text{there is no difference between groups})</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0119259999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class=mord ><span class="mord text"><span class=mord >D</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.761926em;"><span style="top:-3.1362300000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >there is no difference between groups</span></span><span class=mclose >)</span></span></span></span></p> <li><p>Regression: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><msup><mtext>D</mtext><mo>∗</mo></msup><mo>∣</mo><mtext>the coefficient is zero</mtext><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(\text{D}^* \mid \text{the coefficient is zero})</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0119259999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class=mord ><span class="mord text"><span class=mord >D</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.761926em;"><span style="top:-3.1362300000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >the coefficient is zero</span></span><span class=mclose >)</span></span></span></span></p> <li><p>Shapiro-Wilk: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><msup><mtext>D</mtext><mo>∗</mo></msup><mo>∣</mo><mtext>the sample follows a normal distribution</mtext><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(\text{D}^* \mid \text{the sample follows a normal distribution})</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0119259999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class=mord ><span class="mord text"><span class=mord >D</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.761926em;"><span style="top:-3.1362300000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >the sample follows a normal distribution</span></span><span class=mclose >)</span></span></span></span></p> </ul> <p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is the probability of the data you obtained given that the null hypothesis is true. For those who like mathematical formalism: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mi>P</mi><mo stretchy=false >(</mo><msup><mtext>D</mtext><mo>∗</mo></msup><mo>∣</mo><msub><mi>H</mi><mn>0</mn></msub><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">p = P(\text{D}^* \mid H_0)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.0119259999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class=mord ><span class="mord text"><span class=mord >D</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.761926em;"><span style="top:-3.1362300000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mclose >)</span></span></span></span>. In English, this expression means &quot;the probability of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mtext>D</mtext><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\text{D}^*</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.761926em;vertical-align:0em;"></span><span class=mord ><span class="mord text"><span class=mord >D</span></span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.761926em;"><span style="top:-3.1362300000000003em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> conditioned to <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">H_0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.83333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>&quot;. Before moving on to some examples and attempts to formalize an intuition about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values, it is important to note that <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values say something about <strong>data</strong> and not <strong>hypotheses</strong>. For <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value, <strong>the null hypothesis is true, and we are only evaluating whether the data conforms to this null hypothesis or not</strong>. If you leave this tutorial armed with this intuition, the world will be rewarded with researchers better prepared to qualify and interpret evidence &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&lt;</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">p &lt;0.05</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >&lt;</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0.05</span></span></span></span>&#41;.</p> <div class=note ><div class=title >⚠ Note</div> <div class=content ><p><strong>Intuitive Example</strong> of a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value:</p> <p>Imagine that you have a coin that you suspect is biased towards a higher probability of flipping &quot;heads&quot; than &quot;tails&quot;. &#40;Your null hypothesis is then that the coin is fair.&#41; You flip the coin 100 times and get more heads than tails. The <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value will not tell you if the coin is fair, but it will tell you the probability that you will get at least as many heads as if the coin were fair. That&#39;s it - nothing more.</p></div></div> <h4 id=p-values_a_historical_perspective ><a href="#p-values_a_historical_perspective" class=header-anchor ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values – A historical perspective</a></h4> <p>There is no way to understand <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values ​​if we do not understand its origins and historical trajectory. The first mention of the term was made by statistician Ronald Fisher<sup id="fnref:fisher"><a href="#fndef:fisher" class=fnref >[18]</a></sup> &#40;figure below&#41;. In 1925, Fisher &#40;Fisher, 1925&#41; defined the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value as an &quot;index that measures the strength of the evidence against the null hypothesis&quot;. To quantify the strength of the evidence against the null hypothesis, Fisher defended &quot;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&lt;</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">p &lt;0.05</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >&lt;</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0.05</span></span></span></span> &#40;5&#37; significance&#41; as a standard level to conclude that there is evidence against the tested hypothesis, although not as an absolute rule&quot;. Fisher did not stop there but rated the strength of the evidence against the null hypothesis. He proposed &quot;if <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> is between 0.1 and 0.9 there is certainly no reason to suspect the hypothesis tested. If it is below 0.02 it is strongly indicated that the hypothesis fails to account for the whole of the facts. We shall not often be astray if we draw a conventional line at 0.05&quot;. Since Fisher made this statement almost 100 years ago, the 0.05 threshold has been used by researchers and scientists worldwide and it has become ritualistic to use 0.05 as a threshold as if other thresholds could not be used or even considered.</p> <p><img src="/Bayesian-Julia/pages/images/fisher.jpg" alt="Ronald Fisher" /></p> <p><div class=text-center ><em>Ronald Fisher</em></div> <br/></p> <p>After that, the threshold of 0.05, now established as unquestionable, strongly influenced statistics and science. But there is no reason against adopting other thresholds &#40;<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>&#41; like 0.1 or 0.01 &#40;Lakens et al., 2018&#41;. If well argued, the choice of thresholds other than 0.05 can be welcomed by editors, reviewers and advisors. Since the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is a probability, it is a continuous quantity. There is no reason to differentiate a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> of 0.049 against a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> of 0.051. Robert Rosenthal, a psychologist already said &quot;God loves <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> 0.06 as much as a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> 0.05&quot; &#40;Rosnow &amp; Rosenthal, 1989&#41;.</p> <p>In the last year of his life, Fisher published an article &#40;Fisher, 1962&#41; examining the possibilities of Bayesian methods, but with a prior probabilities to be determined experimentally. Some authors even speculate &#40;Jaynes, 2003&#41; that if Fisher were alive today, he would probably be a &quot;Bayesian&quot;.</p> <h3 id=what_the_p-value_is_not ><a href="#what_the_p-value_is_not" class=header-anchor >What the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is not</a></h3> <p><img src="/Bayesian-Julia/pages/images/meme-pvalue.jpg" alt=meme-pvalue  /></p> <p>With the definition and a well-anchored intuition of what <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is, we can move on to what the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value <strong>is not</strong>&#33;</p> <ol> <li><p><strong><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is not the probability of the null hypothesis</strong> - Famous confusion between <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>D</mi><mo>∣</mo><msub><mi>H</mi><mn>0</mn></msub><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(D \mid H_0)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mclose >)</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><msub><mi>H</mi><mn>0</mn></msub><mo>∣</mo><mi>D</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(H_0 \mid D)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class=mclose >)</span></span></span></span>. <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is not the probability of the null hypothesis, but the probability of the data you obtained. To get the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><msub><mi>H</mi><mn>0</mn></msub><mo>∣</mo><mi>D</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(H_0 \mid D)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class=mclose >)</span></span></span></span> you need Bayesian statistics.</p> <li><p><strong><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is not the probability of the data being produced by chance</strong> - No&#33; Nobody said anything of &quot;being produced by chance&quot;. Again: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is the probability to get results at least as extreme as those that were observed, given that the null hypothesis is true.</p> <li><p><strong><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value measures the size of the effect of a statistical test</strong> - Also wrong... <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value does not say anything about the size of the effect. Just about whether the observed data differs from what is expected under the null hypothesis. It is clear that large effects are more likely to be statistically significant than small effects. But this is not a rule and never judge a finding by its <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value, but by its effect size. In addition, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values ​​can be &quot;hacked&quot; in a number of ways &#40;Head et al., 2015&#41; and often their value is a direct consequence of the sample size.</p> </ol> <h3 id=confidence_intervals ><a href="#confidence_intervals" class=header-anchor >Confidence Intervals</a></h3> <p>To conclude, let&#39;s talk about the famous <strong>confidence intervals</strong>, which are not a measure that quantifies the uncertainty of the value of a parameter &#40;remember probabilistic conjectures about parameters are prohibited in frequentist-land&#41;. Wait for it&#33; Here is the definition of confidence intervals:</p> <blockquote> <p>&quot;An X&#37; confidence interval for a parameter <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> is an interval <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>L</mi><mo separator=true >,</mo><mi>U</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(L, U)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal">L</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class=mclose >)</span></span></span></span> generated by a procedure that in repeated sampling has an X&#37; probability of containing the true value of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>, for all possible values of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>.&quot; <br/> <br/> Jerzy Neyman, the &quot;father&quot; of confidence intervals &#40;see figure below&#41; &#40;Neyman, 1937&#41;.</p> </blockquote> <p><img src="/Bayesian-Julia/pages/images/neyman.jpeg" alt="Jerzy Neyman" /></p> <p><div class=text-center ><em>Jerzy Neyman</em></div> <br/></p> <p>Again the idea of sampling an infinite number of times from a population you have never seen. For example: let&#39;s say that you performed a statistical analysis to compare the effectiveness of a public policy in two groups and you obtained the difference between the average of those groups. You can express this difference as a confidence interval. We generally choose 95&#37; confidence &#40;since it is analogous as <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&lt;</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">p &lt; 0.05</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >&lt;</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0.05</span></span></span></span>&#41;. You then write in your paper that the &quot;observed difference between groups is 10.5 - 23.5 &#40;95&#37; CI&#41;.&quot; This means that approximately 95 studies out of 100 would compute a confidence interval that contains the true mean difference –- but it says nothing about which ones those are &#40;whereas the data might&#41;. In other words, 95&#37; is not the probability of obtaining data such that the estimate of the true parameter is contained in the interval that we obtained, it is the probability of obtaining data such that, if we compute another confidence interval in the same way, it contains the true parameter. The interval that we got in this particular instance is irrelevant and might as well be thrown away.</p> <h4 id=confidence_intervals_frequentist_vs_credible_intervals_bayesian ><a href="#confidence_intervals_frequentist_vs_credible_intervals_bayesian" class=header-anchor >Confidence Intervals &#40;Frequentist&#41; vs Credible Intervals &#40;Bayesian&#41;</a></h4> <p>Bayesian statistics have a concept similar to the confidence intervals of frequentist statistics. This concept is called <strong>credibility interval</strong>. And, unlike the confidence interval, its definition is intuitive. <strong>Credibility interval</strong> measures an interval in which we are sure that the value of the parameter of interest is, based on the likelihood conditioned on the observed data - <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>y</mi><mo>∣</mo><mi>θ</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(y \mid \theta)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mclose >)</span></span></span></span>; and the prior probability of the parameter of interest - <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>θ</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(\theta)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mclose >)</span></span></span></span>. It is basically a &quot;slice&quot; of the posterior probability of the parameter restricted to a certain level of certainty. For example: a 95&#37; credibility interval shows the interval that we are 95&#37; sure that captures the value of our parameter of interest. That simple...</p> <p>For example, see figure below, which shows a Log-Normal distribution with mean 0 and standard deviation 2. The green dot shows the maximum likelihood estimation &#40;MLE&#41; of the value of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> which is simply the mode of distribution. And in the shaded area we have the 50&#37; credibility interval of the value of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>, which is the interval between the 25&#37; percentile and the 75&#37; percentile of the probability density of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>. In this example, MLE leads to estimated values that are not consistent with the actual probability density of the value of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>.</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> CairoMakie
<span class=hljs-keyword >using</span> Distributions

d = LogNormal(<span class=hljs-number >0</span>, <span class=hljs-number >2</span>)
range_d = <span class=hljs-number >0</span>:<span class=hljs-number >0.001</span>:<span class=hljs-number >4</span>
q25 = quantile(d, <span class=hljs-number >0.25</span>)
q75 = quantile(d, <span class=hljs-number >0.75</span>)
credint = range(q25; stop=q75, length=<span class=hljs-number >100</span>)
f, ax, l = lines(
    range_d,
    pdf.(d, range_d);
    linewidth=<span class=hljs-number >3</span>,
    axis=(; limits=(-<span class=hljs-number >0.2</span>, <span class=hljs-number >4.2</span>, <span class=hljs-literal >nothing</span>, <span class=hljs-literal >nothing</span>), xlabel=<span class=hljs-string >L&quot;\theta&quot;</span>, ylabel=<span class=hljs-string >&quot;Density&quot;</span>),
)
scatter!(ax, mode(d), pdf(d, mode(d)); color=:green, markersize=<span class=hljs-number >12</span>)
band!(ax, credint, <span class=hljs-number >0.0</span>, pdf.(d, credint); color=(:steelblue, <span class=hljs-number >0.5</span>))</code></pre> <p><img src="/Bayesian-Julia/assets/pages/02_bayes_stats/code/output/lognormal.svg" alt=""> <div class=text-center ><em><strong>Log-Normal</strong>: Maximum Likelihood Estimate vs Credible Intervals</em></div> <br/></p> <p>Now an example of a multimodal distribution<sup id="fnref:multimodal"><a href="#fndef:multimodal" class=fnref >[19]</a></sup>. The figure below shows a bimodal distribution with two modes 2 and 10<sup id="fnref:multimodal2"><a href="#fndef:multimodal2" class=fnref >[20]</a></sup> The green dot shows the maximum likelihood estimation &#40;MLE&#41; of the value of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> which is the mode of distribution. See that even with 2 modes, maximum likelihood defaults to the highest mode<sup id="fnref:multimodal3"><a href="#fndef:multimodal3" class=fnref >[21]</a></sup>. And in the shaded area we have the 50&#37; credibility interval of the value of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>, which is the interval between the 25&#37; percentile and the 75&#37; percentile of the probability density of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>. In this example, estimation by maximum likelihood again lead us to estimated values ​​that are not consistent with the actual probability density of the value of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>.</p> <pre><code class="julia hljs">d1 = Normal(<span class=hljs-number >10</span>, <span class=hljs-number >1</span>)
d2 = Normal(<span class=hljs-number >2</span>, <span class=hljs-number >1</span>)
mix_d = [<span class=hljs-number >0.4</span>, <span class=hljs-number >0.6</span>]
d = MixtureModel([d1, d2], mix_d)
range_d = -<span class=hljs-number >2</span>:<span class=hljs-number >0.01</span>:<span class=hljs-number >14</span>
sim_d = rand(d, <span class=hljs-number >10_000</span>)
q25 = quantile(sim_d, <span class=hljs-number >0.25</span>)
q75 = quantile(sim_d, <span class=hljs-number >0.75</span>)
credint = range(q25; stop=q75, length=<span class=hljs-number >100</span>)

f, ax, l = lines(
    range_d,
    pdf.(d, range_d);
    linewidth=<span class=hljs-number >3</span>,
    axis=(;
        limits=(-<span class=hljs-number >2</span>, <span class=hljs-number >14</span>, <span class=hljs-literal >nothing</span>, <span class=hljs-literal >nothing</span>),
        xticks=[<span class=hljs-number >0</span>, <span class=hljs-number >5</span>, <span class=hljs-number >10</span>],
        xlabel=<span class=hljs-string >L&quot;\theta&quot;</span>,
        ylabel=<span class=hljs-string >&quot;Density&quot;</span>,
    ),
)
scatter!(ax, mode(d2), pdf(d, mode(d2)); color=:green, markersize=<span class=hljs-number >12</span>)
band!(ax, credint, <span class=hljs-number >0.0</span>, pdf.(d, credint); color=(:steelblue, <span class=hljs-number >0.5</span>))</code></pre> <p><img src="/Bayesian-Julia/assets/pages/02_bayes_stats/code/output/mixture.svg" alt=""> <div class=text-center ><em><strong>Mixture</strong>: Maximum Likelihood Estimate vs Credible Intervals</em></div> <br/></p> <h2 id=bayesian_statistics_vs_frequentist_statistics ><a href="#bayesian_statistics_vs_frequentist_statistics" class=header-anchor >Bayesian Statistics vs Frequentist Statistics</a></h2> <p>What we&#39;ve seen so fat can be resumed in the table below:</p> <table><tr><th align=right ><th align=right ><strong>Bayesian Statistics</strong><th align=right ><strong>Frequentist Statistics</strong><tr><td align=right ><strong>Data</strong><td align=right >Fixed – Non-random<td align=right >Uncertain – Random<tr><td align=right ><strong>Parameters</strong><td align=right >Uncertain – Random<td align=right >Fixed – Non-random<tr><td align=right ><strong>Inference</strong><td align=right >Uncertainty over parameter values<td align=right >Uncertainty over a sampling procedure from an infinite population<tr><td align=right ><strong>Probability</strong><td align=right >Subjective<td align=right >Objective &#40;but with strong model assumptions&#41;<tr><td align=right ><strong>Uncertainty</strong><td align=right >Credible Interval – <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>θ</mi><mo>∣</mo><mi>y</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(\theta \mid y)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mclose >)</span></span></span></span><td align=right >Confidence Interval – <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy=false >(</mo><mi>y</mi><mo>∣</mo><mi>θ</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">P(y \mid \theta)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∣</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class=mclose >)</span></span></span></span></table> <h2 id=advantages_of_bayesian_statistics ><a href="#advantages_of_bayesian_statistics" class=header-anchor >Advantages of Bayesian Statistics</a></h2> <p>Finally, I summarize the main <strong>advantages of Bayesian statistics</strong>:</p> <ul> <li><p>Natural approach to express uncertainty</p> <li><p>Ability to incorporate prior information</p> <li><p>Greater model flexibility</p> <li><p>Complete posterior distribution of parameters</p> <ul> <li><p>Confidence Intervals vs Credibility Intervals</p> </ul> <li><p>Natural propagation of uncertainty</p> </ul> <p>And I believe that I also need to show the main <strong>disadvantage</strong>:</p> <ul> <li><p>Slow model estimation speed &#40;30 seconds instead of 3 seconds using the frequentist approach&#41;</p> </ul> <h2 id=the_beginning_of_the_end_of_frequentist_statistics ><a href="#the_beginning_of_the_end_of_frequentist_statistics" class=header-anchor >The beginning of the end of Frequentist Statistics</a></h2> <p><div class=text-center ><em>Götterdämmerung</em></div> <br/></p> <p>Dear reader, know that you are at a time in history when Statistics is undergoing <strong>major changes</strong>. I believe that frequentist statistics, especially the way we qualify evidence and hypotheses with <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values, will transform in a &quot;significant&quot; way. Five years ago, the American Statistical Association &#40;ASA, the world&#39;s largest professional statistical organization&#41; published a statement on <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values &#40;Wasserstein &amp; Lazar, 2016&#41;. The statement says exactly what we talk about here. The main concepts of the null hypothesis significance test, and in particular <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values, fail to provide what researchers require of them. Despite what many statistical books, teaching materials and published articles say, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values ​​below 0.05 do not &quot;prove&quot; the reality of anything. Nor, at this point, do the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values ​​above 0.05 refute anything. ASA&#39;s statement has more than 3,600 citations causing significant impact. As an example, an international symposium was held in 2017 that led to a special open access edition of <em>The American Statistician</em> dedicated to practical ways to abandon <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&lt;</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">p &lt;0.05</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >&lt;</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0.05</span></span></span></span> &#40;Wasserstein, Schirm &amp; Lazar 2019&#41;.</p> <p>Soon after, more attempts and claims followed. In September 2017, <em>Nature Human Behavior</em> published an editorial proposing that the significance level of the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value be reduced from <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.05</mn></mrow><annotation encoding="application/x-tex">0.05</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0.05</span></span></span></span> to <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.005</mn></mrow><annotation encoding="application/x-tex">0.005</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0.005</span></span></span></span> &#40;Benjamin et al., 2018&#41;. Several authors, including many highly influential and important statisticians, have argued that this simple step would help tackle the problem of the science replicability crisis, which many believe is the main consequence of the abusive use of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values &#40;Ioannidis, 2019&#41;. In addition, many have gone a step further and suggest that science discard once and for all <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values &#40;Nature, 2019&#41;. Many suggest &#40;myself included&#41; that the main inference tool be Bayesian statistics &#40;Amrhein, Greenland &amp; McShane, 2019; Goodman, 2016; van de Schoot et al., 2021&#41;</p> <h2 id=turing ><a href="#turing" class=header-anchor >Turing</a></h2> <p><a href="https://turing.ml/">Turing</a> &#40;Ge, Xu &amp; Ghahramani, 2018&#41; is a <strong>probabilistic programming interface written in Julia</strong> &#40;Bezanson, Edelman, Karpinski &amp; Shah, 2017&#41;. It enables <strong>intuitive modeling syntax</strong> with <strong>flexible composable probabilistic programming inference</strong>. Turing supports a wide range of <strong>sampling based inference algorithms</strong> by <strong>combining model inference with differentiable programming interfaces</strong> in Julia. Yes, Julia is that amazing. The same differentiable stuff that you develop for optimization in neural networks you can plug it in to a probabilistic programming framework and it will work <em>without</em> much effort and boiler-plate code. Most importantly, Turing inference is <strong>composable</strong>: it combines Markov chain sampling operations on subsets of model variables, e.g. using a combination of a Hamiltonian Monte Carlo &#40;HMC&#41; engine and a particle Gibbs &#40;PG&#41; engine. This composable inference engine allows the user to <strong>easily switch</strong> between black-box style inference methods such as HMC, and customized inference methods.</p> <p>I believe Turing is the most <strong>important and popular probabilistic language framework in Julia</strong>. It is what PyMC3 and Stan are for Python and R, but for Julia. Furthermore, you don&#39;t have to do &quot;cartwheels&quot; with Theano backends and tensors like in PyMC3 or learn a new language to declare your models like in Stan &#40;or even have to debug C&#43;&#43; stuff&#41;. Turing is <strong>all</strong> Julia. It uses Julia arrays, Julia distributions, Julia autodiff, Julia plots, Julia random number generator, Julia MCMC algorithms etc. I think that developing and estimating Bayesian probabilistic models using Julia and Turing is <strong>powerful</strong>, <strong>intuitive</strong>, <strong>fun</strong>, <strong>expressive</strong> and allows <strong>easily new breakthroughs</strong> simply by being 100&#37; Julia and embedded in Julia ecosystem. As discussed in <a href="/Bayesian-Julia/pages/1_why_Julia/">1. <strong>Why Julia?</strong></a>, having multiple dispatch with LLVM&#39;s JIT compilation allows us to combine code, types and algorithms in a very powerful and yet simple way. By using Turing in this context, a researcher &#40;or a curious Joe&#41; can develop new methods and extend the frontiers of Bayesian inference with new models, samplers, algorithms, or any mix-match of those.</p> <h2 id=footnotes ><a href="#footnotes" class=header-anchor >Footnotes</a></h2> <p><table class=fndef  id="fndef:evidencebased"> <tr> <td class=fndef-backref ><a href="#fnref:evidencebased">[1]</a> <td class=fndef-content >personally, like a good Popperian, I don&#39;t believe there is science without being evidence-based; what does not use evidence can be considered as logic, philosophy or social practices &#40;no less or more important than science, just a demarcation of what is science and what is not; eg, mathematics and law&#41;. </table> <table class=fndef  id="fndef:computingpower"> <tr> <td class=fndef-backref ><a href="#fnref:computingpower">[2]</a> <td class=fndef-content >your smartphone &#40;iPhone 12 - 4GB RAM&#41; has 1,000,000x &#40;1 million&#41; more computing power than the computer that was aboard the Apollo 11 &#40;4kB RAM&#41; which took the man to the moon. Detail: this on-board computer was responsible for lunar module navigation, route and controls. </table> <table class=fndef  id="fndef:deFinetti"> <tr> <td class=fndef-backref ><a href="#fnref:deFinetti">[3]</a> <td class=fndef-content >if the reader wants an in-depth discussion see Nau &#40;2001&#41;. </table> <table class=fndef  id="fndef:subjective"> <tr> <td class=fndef-backref ><a href="#fnref:subjective">[4]</a> <td class=fndef-content >my observation: related to the subjective Bayesian approach. </table> <table class=fndef  id="fndef:objective"> <tr> <td class=fndef-backref ><a href="#fnref:objective">[5]</a> <td class=fndef-content >my observation: related to the objective frequentist approach. </table> <table class=fndef  id="fndef:realnumber"> <tr> <td class=fndef-backref ><a href="#fnref:realnumber">[6]</a> <td class=fndef-content >a number that can be expressed as a point on a continuous line that originates from minus infinity and ends and plus infinity <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mo>−</mo><mi mathvariant=normal >∞</mi><mo separator=true >,</mo><mo>+</mo><mi mathvariant=normal >∞</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(-\infty, +\infty)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class=mord >−</span><span class=mord >∞</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord >+</span><span class=mord >∞</span><span class=mclose >)</span></span></span></span>; for those who like computing it is a floating point <code>float</code> or<code>double</code>. </table> <table class=fndef  id="fndef:mutually"> <tr> <td class=fndef-backref ><a href="#fnref:mutually">[7]</a> <td class=fndef-content ><em>i.e.</em> the events are &quot;mutually exclusive&quot;. That means that only <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> or <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> can occur in the whole sample space. </table> <table class=fndef  id="fndef:axioms"> <tr> <td class=fndef-backref ><a href="#fnref:axioms">[8]</a> <td class=fndef-content >in mathematics, axioms are assumptions assumed to be true that serve as premises or starting points for the elaboration of arguments and theorems. Often the axioms are questionable, for example non-Euclidean geometry refutes Euclid&#39;s fifth axiom on parallel lines. So far there is no questioning that has supported the scrutiny of time and science about the three axioms of probability. </table> <table class=fndef  id="fndef:mutually2"> <tr> <td class=fndef-backref ><a href="#fnref:mutually2">[9]</a> <td class=fndef-content >for example, the result of a given coin is one of two mutually exclusive events: heads or tails. </table> <table class=fndef  id="fndef:thomaspricelaplace"> <tr> <td class=fndef-backref ><a href="#fnref:thomaspricelaplace">[10]</a> <td class=fndef-content >the formal name of the theorem is Bayes-Price-Laplace, as Thomas Bayes was the first to discover, Richard Price took his drafts, formalized in mathematical notation and presented to the Royal Society of London, and Pierre Laplace rediscovered the theorem without having had previous contact in the late 18th century in France by using probability for statistical inference with Census data in the Napoleonic era. </table> <table class=fndef  id="fndef:prior"> <tr> <td class=fndef-backref ><a href="#fnref:prior">[11]</a> <td class=fndef-content >I will cover prior probabilities in the content of tutorial <a href="/Bayesian-Julia/pages/4_Turing/">4. <strong>How to use Turing</strong></a>. </table> <table class=fndef  id="fndef:warning"> <tr> <td class=fndef-backref ><a href="#fnref:warning">[12]</a> <td class=fndef-content >I warned you that it was not intuitive... </table> <table class=fndef  id="fndef:likelihoodsubj"> <tr> <td class=fndef-backref ><a href="#fnref:likelihoodsubj">[13]</a> <td class=fndef-content >something worth noting: likelihood also carries <strong>a lot of subjectivity</strong>. </table> <table class=fndef  id="fndef:likelihoodopt"> <tr> <td class=fndef-backref ><a href="#fnref:likelihoodopt">[14]</a> <td class=fndef-content >for those who have a thing for mathematics &#40;like myself&#41;, we calculate at which point of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> the derivative of the likelihood function is zero - <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant=script >L</mi><mo mathvariant=normal >′</mo></msup><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\mathcal{L}^\prime = 0</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.751892em;vertical-align:0em;"></span><span class=mord ><span class="mord mathcal">L</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0</span></span></span></span>. So we are talking really about an optimization problem that for some likelihood functions we can have a closed-form analytical solution. </table> <table class=fndef  id="fndef:warning2"> <tr> <td class=fndef-backref ><a href="#fnref:warning2">[15]</a> <td class=fndef-content >have I forgot to warn you that it is not so intuitive? </table> <table class=fndef  id="fndef:booksp"> <tr> <td class=fndef-backref ><a href="#fnref:booksp">[16]</a> <td class=fndef-content >there are several statistics textbooks that have wrong definitions of what a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-value is. If you don&#39;t believe me, see Wasserstein &amp; Lazar &#40;2016&#41;. </table> <table class=fndef  id="fndef:gelman"> <tr> <td class=fndef-backref ><a href="#fnref:gelman">[17]</a> <td class=fndef-content >this duality is attributed to Andrew Gelman – Bayesian statistician. </table> <table class=fndef  id="fndef:fisher"> <tr> <td class=fndef-backref ><a href="#fnref:fisher">[18]</a> <td class=fndef-content >Ronald Fisher&#39;s personality and life controversy deserves a footnote. His contributions were undoubtedly crucial to the advancement of science and statistics. His intellect was brilliant and his talent already flourished young: before turning 33 years old he had proposed the maximum likelihood estimation method &#40;MLE&#41; &#40;Stigler, 2007&#41; and also created the concept of degrees of freedom when proposing a correction in Pearson&#39;s chi-square test &#40;Baird, 1983&#41;. He also invented the Analysis of Variance &#40;ANOVA&#41; and was the first to propose randomization as a way of carrying out experiments, being considered the &quot;father&quot; of randomized clinical trials &#40;RCTs&#41;. Not everything is golden in Fisher&#39;s life, he was a eugenicist and had a very strong view on ethnicity and race, advocating the superiority of certain ethnicities. Furthermore, he was extremely invariant, chasing, harming and mocking any critic of his theories and publications. What we see today in the monopoly of the Neyman-Pearson paradigm &#40;Neyman &amp; Pearson, 1933&#41; with <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-values ​​and null hypotheses the result of this Fisherian effort to silence critics and let only his voice echo. </table> <table class=fndef  id="fndef:multimodal"> <tr> <td class=fndef-backref ><a href="#fnref:multimodal">[19]</a> <td class=fndef-content >which is not uncommon to see in the real world. </table> <table class=fndef  id="fndef:multimodal2"> <tr> <td class=fndef-backref ><a href="#fnref:multimodal2">[20]</a> <td class=fndef-content >for the curious it is a mixture of two normal distributions both with standard deviation 1, but with different means. To complete it assigns the weights of 60&#37; for the distribution with an average of 2 and 40&#37; for the distribution with an average of 10. </table> <table class=fndef  id="fndef:multimodal3"> <tr> <td class=fndef-backref ><a href="#fnref:multimodal3">[21]</a> <td class=fndef-content >to be more precise, estimation by maximum likelihood in non-convex functions cannot find an analytical solution and, if we are going to use another iterative maximization procedure, there is a risk of it becoming stuck in the second – lower-valued – mode of distribution. </table> </p> <h2 id=references ><a href="#references" class=header-anchor >References</a></h2> <p>Amrhein, V., Greenland, S., &amp; McShane, B. &#40;2019&#41;. Scientists rise up against statistical significance. <em>Nature</em>, 567&#40;7748&#41;, 305–307. https://doi.org/10.1038/d41586-019-00857-9</p> <p>Baird, D. &#40;1983&#41;. The fisher/pearson chi-squared controversy: A turning point for inductive inference. <em>The British Journal for the Philosophy of Science</em>, 34&#40;2&#41;, 105–118.</p> <p>Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., … Johnson, V. E. &#40;2018&#41;. Redefine statistical significance. <em>Nature Human Behaviour</em>, 2&#40;1&#41;, 6–10. https://doi.org/10.1038/s41562-017-0189-z</p> <p>Bezanson, J., Edelman, A., Karpinski, S., &amp; Shah, V. B. &#40;2017&#41;. Julia: A fresh approach to numerical computing. SIAM Review, 59&#40;1&#41;, 65–98.</p> <p>de Finetti, B. &#40;1974&#41;. <em>Theory of Probability</em>. New York: John Wiley &amp; Sons.</p> <p>Eckhardt, R. &#40;1987&#41;. Stan Ulam, John von Neumann, and the Monte Carlo Method. <em>Los Alamos Science</em>, 15&#40;30&#41;, 131–136.</p> <p>Fisher, R. A. &#40;1925&#41;. <em>Statistical methods for research workers</em>. Oliver; Boyd.</p> <p>Fisher, R. A. &#40;1962&#41;. Some Examples of Bayes’ Method of the Experimental Determination of Probabilities A Priori. <em>Journal of the Royal Statistical Society. Series B &#40;Methodological&#41;</em>, 24&#40;1&#41;, 118–124. Retrieved from https://www.jstor.org/stable/2983751</p> <p>Ge, H., Xu, K., &amp; Ghahramani, Z. &#40;2018&#41;. Turing: A Language for Flexible Probabilistic Inference. International Conference on Artificial Intelligence and Statistics, 1682–1690. http://proceedings.mlr.press/v84/ge18b.html</p> <p>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. &#40;2013&#41;. <em>Bayesian Data Analysis</em>. Chapman and Hall/CRC.</p> <p>Goodman, S. N. &#40;2016&#41;. Aligning statistical and scientific reasoning. <em>Science</em>, 352&#40;6290&#41;, 1180–1181. https://doi.org/10.1126/science.aaf5406</p> <p>Head, M. L., Holman, L., Lanfear, R., Kahn, A. T., &amp; Jennions, M. D. &#40;2015&#41;. The extent and consequences of p-hacking in science. <em>PLoS Biol</em>, 13&#40;3&#41;, e1002106.</p> <p>Ioannidis, J. P. A. &#40;2019&#41;. What Have We &#40;Not&#41; Learnt from Millions of Scientific Papers with &lt;i&gt;P&lt;/i&gt; Values? <em>The American Statistician</em>, 73&#40;sup1&#41;, 20–25. https://doi.org/10.1080/00031305.2018.1447512</p> <p>It’s time to talk about ditching statistical significance. &#40;2019&#41;. <em>Nature</em>, 567&#40;7748, 7748&#41;, 283–283. https://doi.org/10.1038/d41586-019-00874-8</p> <p>Jaynes, E. T. &#40;2003&#41;. <em>Probability theory: The logic of science</em>. Cambridge university press.</p> <p>Kolmogorov, A. N. &#40;1933&#41;. <em>Foundations of the Theory of Probability</em>. Berlin: Julius Springer.</p> <p>Lakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., … Zwaan, R. A. &#40;2018&#41;. Justify your alpha. <em>Nature Human Behaviour</em>, 2&#40;3&#41;, 168–171. https://doi.org/10.1038/s41562-018-0311-x</p> <p>Nau, R. F. &#40;2001&#41;. De Finetti was Right: Probability Does Not Exist. <em>Theory and Decision</em>, 51&#40;2&#41;, 89–124. https://doi.org/10.1023/A:1015525808214</p> <p>Neyman, J. &#40;1937&#41;. Outline of a theory of statistical estimation based on the classical theory of probability. <em>Philosophical Transactions of the Royal Society of London</em>. Series A, Mathematical and Physical Sciences, 236&#40;767&#41;, 333–380.</p> <p>Neyman, J., &amp; Pearson, E. S. &#40;1933&#41;. On the problem of the most efficient tests of statistical hypotheses. <em>Philosophical Transactions of the Royal Society of London</em>. Series A, Containing Papers of a Mathematical or Physical Character, 231&#40;694-706&#41;, 289–337.</p> <p>Rosnow, R. L., &amp; Rosenthal, R. &#40;1989&#41;. Statistical procedures and the justification of knowledge in psychological science. <em>American Psychologist</em>, 44, 1276–1284.</p> <p>Stigler, S. M. &#40;2007&#41;. The epic story of maximum likelihood. <em>Statistical Science</em>, 22&#40;4&#41;, 598–620.</p> <p>van de Schoot, R., Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., … Yau, C. &#40;2021&#41;. Bayesian statistics and modelling. <em>Nature Reviews Methods Primers</em>, 1&#40;1, 1&#41;, 1–26. https://doi.org/10.1038/s43586-020-00001-2</p> <p>Wasserstein, R. L., &amp; Lazar, N. A. &#40;2016&#41;. The ASA’s Statement on p-Values: Context, Process, and Purpose. <em>American Statistician</em>, 70&#40;2&#41;, 129–133. https://doi.org/10.1080/00031305.2016.1154108</p> <p>Wasserstein, R. L., Schirm, A. L., &amp; Lazar, N. A. &#40;2019&#41;. Moving to a World Beyond &quot;p &lt; 0.05.&quot; <em>American Statistician</em>, 73, 1–19. https://doi.org/10.1080/00031305.2019.1583913</p> <div class=page-foot > <div class=copyright > Last modified: October 26, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </div> </div> <!-- end of class page-wrap-->